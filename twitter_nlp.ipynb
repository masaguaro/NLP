{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter NLP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, string\n",
    "import platform\n",
    "from collections import Counter\n",
    "import itertools as it\n",
    "from twitter_client import get_twitter_client\n",
    "from tweepy import Cursor\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from selectfile import FileBrowser\n",
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = get_twitter_client()\n",
    "#print(client.me())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data using Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#twitter_user = input('Please introduce the twitter user name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(twitter_user)\n",
    "# cwd = os.getcwd()\n",
    "# if os.path.isdir(os.path.join(cwd,'raw_data')):\n",
    "#     fname = os.path.join(cwd, 'raw_data', 'user_timeline_{}.jsonl'.format(twitter_user)) \n",
    "# else:\n",
    "#     fname = os.path.join(os.mkdir(os.path.join(cwd,'raw_data')), 'user_timeline_{}.jsonl'.format(twitter_user ))   \n",
    "    \n",
    "# print(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(fname, 'w') as f:\n",
    "#     for page in Cursor(client.user_timeline, screen_name=twitter_user, count=200).pages(16):\n",
    "#         for status in page:\n",
    "#             f.write(json.dumps(status._json) + \"\\n\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e36e228e1e0b4f67b42b41e75a392d45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>C:\\\\Users\\\\Rodolfo\\\\Desktop\\\\NLP</h2>'), Button(description='..', style=ButtonS…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_data_file = FileBrowser()\n",
    "raw_data_file.widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Rodolfo\\\\Desktop\\\\NLP\\\\raw_data\\\\user_timeline_jeremycorbyn.jsonl'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data_file\n",
    "raw_data_file.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(tokenizer, text, stopwords=[]):\n",
    "    \"\"\"Process the text of a tweet:\n",
    "    - Lowercase\n",
    "    - Tokenize\n",
    "    - Stopword removal\n",
    "    - Digits removal\n",
    "    Return: list of strings\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    tokens = tokenizer(text)\n",
    "    #print(tokens)\n",
    "    return [tok for tok in tokens if tok not in stopwords and not tok.isdigit()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "…: 2295\n",
      "labour: 728\n",
      "’: 433\n",
      "today: 429\n",
      "people: 330\n",
      "government: 313\n",
      "@uklabour: 300\n",
      "tories: 247\n",
      "nhs: 210\n",
      "@theresa_may: 199\n",
      "country: 166\n",
      "us: 166\n",
      "great: 153\n",
      "tory: 144\n",
      "vote: 143\n",
      "#forthemany: 131\n",
      "must: 130\n",
      "years: 129\n",
      "campaign: 127\n",
      "many: 115\n"
     ]
    }
   ],
   "source": [
    "tweet_tokenizer = TweetTokenizer()\n",
    "punct = list(string.punctuation)\n",
    "stopword_list = stopwords.words('english') + punct + ['rt', 'via', '...']\n",
    "tf = Counter()\n",
    "with open(raw_data_file.path, 'r') as f:\n",
    "    for line in f:\n",
    "        tweet = json.loads(line)\n",
    "        tokens = process(tweet_tokenizer.tokenize, text=tweet['text'], stopwords=stopword_list)\n",
    "        tf.update(tokens)\n",
    "for tag, count in tf.most_common(20):\n",
    "    print(\"{}: {}\".format(tag, count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.Tagger at 0x2130868be0>),\n",
       " ('parser', <spacy.pipeline.DependencyParser at 0x213090a990>),\n",
       " ('ner', <spacy.pipeline.EntityRecognizer at 0x213090aba0>)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  spaCy sentences contained in each tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Twitter .- 0 RT @RLong_Bailey: Labour's position on #fracking is unequivocal: we will ban it. I have recently visited communities opposed to fracking in… \n",
      "\n",
      "Sentence .- 0 RT @RLong_Bailey:\n",
      "Sentence .- 1 Labour's position on #fracking is unequivocal: we will ban it.\n",
      "Sentence .- 2 I have recently visited communities opposed to fracking in…\n",
      "\n",
      " Twitter .- 1 Businesses creating budget private schools is no way to solve the education crisis - in fact it will only make it w… https://t.co/23MUBEcb7C \n",
      "\n",
      "Sentence .- 0 Businesses creating budget private schools is no way to solve the education crisis - in fact it will only make it w… https://t.co/23MUBEcb7C\n",
      "\n",
      " Twitter .- 2 Tory rail mayhem has gone on too long. https://t.co/vEVZpbkM6O \n",
      "\n",
      "Sentence .- 0 Tory rail mayhem has gone on too long.\n",
      "Sentence .- 1 https://t.co/vEVZpbkM6O\n",
      "\n",
      " Twitter .- 3 Ten years ago, @JohnMcdonnellMP said the banks needed to work for the many not the few.\n",
      "\n",
      "He was right then and is n… https://t.co/oKaXsIsqoV \n",
      "\n",
      "Sentence .- 0 Ten years ago, @JohnMcdonnellMP said the banks needed to work for the many not the few.\n",
      "\n",
      "\n",
      "Sentence .- 1 He was right then and is\n",
      "Sentence .- 2 n\n",
      "Sentence .- 3 …\n",
      "Sentence .- 4 https://t.co/oKaXsIsqoV\n",
      "\n",
      " Twitter .- 4 RT @JonAshworth: More news today on the awful consequences of huge staffing gaps across our NHS. Utterly unacceptable cancer patients force… \n",
      "\n",
      "Sentence .- 0 RT @JonAshworth:\n",
      "Sentence .- 1 More news today on the awful consequences of huge staffing gaps across our NHS.\n",
      "Sentence .- 2 Utterly unacceptable cancer patients force…\n",
      "\n",
      " Twitter .- 5 RT @RLong_Bailey: Our High Streets are dying and the Tories aren't doing anything about it.Our communities, hundreds of thousands of jobs a… \n",
      "\n",
      "Sentence .- 0 RT @RLong_Bailey:\n",
      "Sentence .- 1 Our High Streets are dying and the Tories aren't doing anything about it.\n",
      "Sentence .- 2 Our communities, hundreds of thousands of jobs a…\n",
      "\n",
      " Twitter .- 6 .@Theresa_May's \"deport first, appeal later\" approach has left four children without their father.\n",
      "\n",
      "Under Labour, t… https://t.co/XPYEaOw0an \n",
      "\n",
      "Sentence .- 0 .@Theresa_May's \"deport first, appeal later\" approach has left four children without their father.\n",
      "\n",
      "\n",
      "Sentence .- 1 Under Labour, t… https://t.co/XPYEaOw0an\n",
      "\n",
      " Twitter .- 7 Michael Foot loved this country. That's why he wanted to make it better for everyone.\n",
      "\n",
      "Smearing a dead man, who suc… https://t.co/H5ARmBIIo1 \n",
      "\n",
      "Sentence .- 0 Michael Foot loved this country.\n",
      "Sentence .- 1 That's why he wanted to make it better for everyone.\n",
      "\n",
      "\n",
      "Sentence .- 2 Smearing a dead man, who suc… https://t.co/H5ARmBIIo1\n",
      "\n",
      " Twitter .- 8 Our high streets used to be thriving. \n",
      "\n",
      "Labour will revive our towns and rebuild communities.\n",
      "\n",
      "https://t.co/2ZLJ2nOr8z \n",
      "\n",
      "Sentence .- 0 Our high streets used to be thriving. \n",
      "\n",
      "\n",
      "Sentence .- 1 Labour will revive our towns and rebuild communities.\n",
      "\n",
      "\n",
      "Sentence .- 2 https://t.co/2ZLJ2nOr8z\n"
     ]
    }
   ],
   "source": [
    "tf = Counter()\n",
    "with open(raw_data_file.path, 'r') as f:\n",
    "    sample = it.islice(f, 1, 10)\n",
    "    #for line in f:\n",
    "    for num, line in enumerate(sample):\n",
    "        tweet = json.loads(line)\n",
    "        print('\\n', 'Twitter .-', num, nlp(tweet['text']), '\\n')\n",
    "        for num, sent in enumerate(nlp(tweet['text']).sents):\n",
    "            print('Sentence .-', num, sent)\n",
    "        #print( [tok for tok in nlp(tweet['text'])], '\\n')\n",
    "#         tokens = process(nlp, text=tweet['text'], stopwords=stopword_list)\n",
    "#         tf.update(tokens)\n",
    "# for tag, count in tf.most_common(20):\n",
    "#     print(\"{}: {}\".format(tag, count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  spaCy entity recognition contained in each tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Twitter .- 0 RT @RLong_Bailey: Labour's position on #fracking is unequivocal: we will ban it. I have recently visited communities opposed to fracking in… \n",
      "\n",
      "Entity .- 0 RT @RLong_Bailey - ORG\n",
      "Entity .- 1 Labour - ORG\n",
      "Entity .- 2 # - ORG\n",
      "\n",
      " Twitter .- 1 Businesses creating budget private schools is no way to solve the education crisis - in fact it will only make it w… https://t.co/23MUBEcb7C \n",
      "\n",
      "\n",
      " Twitter .- 2 Tory rail mayhem has gone on too long. https://t.co/vEVZpbkM6O \n",
      "\n",
      "\n",
      " Twitter .- 3 Ten years ago, @JohnMcdonnellMP said the banks needed to work for the many not the few.\n",
      "\n",
      "He was right then and is n… https://t.co/oKaXsIsqoV \n",
      "\n",
      "Entity .- 0 Ten years ago - DATE\n",
      "Entity .- 1 @JohnMcdonnellMP - ORG\n",
      "\n",
      " Twitter .- 4 RT @JonAshworth: More news today on the awful consequences of huge staffing gaps across our NHS. Utterly unacceptable cancer patients force… \n",
      "\n",
      "Entity .- 0 RT - ORG\n",
      "Entity .- 1 today - DATE\n",
      "Entity .- 2 NHS - ORG\n",
      "\n",
      " Twitter .- 5 RT @RLong_Bailey: Our High Streets are dying and the Tories aren't doing anything about it.Our communities, hundreds of thousands of jobs a… \n",
      "\n",
      "Entity .- 0 RT @RLong_Bailey: - ORG\n",
      "Entity .- 1 Tories - NORP\n",
      "Entity .- 2 hundreds of thousands - CARDINAL\n",
      "\n",
      " Twitter .- 6 .@Theresa_May's \"deport first, appeal later\" approach has left four children without their father.\n",
      "\n",
      "Under Labour, t… https://t.co/XPYEaOw0an \n",
      "\n",
      "Entity .- 0 first - ORDINAL\n",
      "Entity .- 1 four - CARDINAL\n",
      "Entity .- 2 Labour - ORG\n",
      "\n",
      " Twitter .- 7 Michael Foot loved this country. That's why he wanted to make it better for everyone.\n",
      "\n",
      "Smearing a dead man, who suc… https://t.co/H5ARmBIIo1 \n",
      "\n",
      "Entity .- 0 Michael Foot - PERSON\n",
      "\n",
      " Twitter .- 8 Our high streets used to be thriving. \n",
      "\n",
      "Labour will revive our towns and rebuild communities.\n",
      "\n",
      "https://t.co/2ZLJ2nOr8z \n",
      "\n",
      "Entity .- 0 Labour - ORG\n"
     ]
    }
   ],
   "source": [
    "with open(raw_data_file.path, 'r') as f:\n",
    "    sample = it.islice(f, 1, 10)\n",
    "    #for line in f:\n",
    "    for num, line in enumerate(sample):\n",
    "        tweet = json.loads(line)\n",
    "        print('\\n', 'Twitter .-', num, nlp(tweet['text']), '\\n')\n",
    "        for num, ent in enumerate(nlp(tweet['text']).ents):\n",
    "            print('Entity .-', num, ent, '-', ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
